# VEXxy Enterprise - Premium VEX Generation Service

**Automated reachability-based VEX generation powered by Kubescape**

**Status:** âœ… MVP Complete - Ready for Testing
**Architecture:** Production-grade Kubescape integration

---

## What This Is

The **VEXxy Premium Service** provides automated, high-confidence VEX (Vulnerability Exploitability eXchange) document generation through runtime analysis. Unlike traditional scanners that only report vulnerabilities, we **prove which ones are actually reachable** in your running containers.

### Value Proposition

> **"The only platform that proves vulnerabilities are unreachable through runtime evidence, not guesses"**

### How It Works

1. **Submit** container image for analysis
2. **Deploy** image in isolated Kubernetes sandbox
3. **Monitor** runtime behavior with Kubescape (eBPF-based)
4. **Analyze** which CVEs are actually reachable
5. **Generate** OpenVEX documents with cryptographic evidence

### Powered by Kubescape

We integrate with [Kubescape](https://kubescape.io), the CNCF-backed open-source tool for Kubernetes security and compliance. Kubescape provides:

- **Runtime analysis** - eBPF monitoring of actual code execution
- **Filtered SBOMs** - Only components actually used at runtime
- **Reachability detection** - High-confidence CVE exploitability analysis
- **VEX generation** - OpenVEX-compliant documents

---

## Repository Structure

```
vexxy-enterprise/
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ PREMIUM_VEX_INTEGRATION_PLAN.md        # Original architecture (reference)
â”œâ”€â”€ KUBESCAPE_INTEGRATION_SUMMARY.md       # What we actually built
â”‚
â””â”€â”€ premium-service/                       # Premium VEX service (COMPLETE)
    â”œâ”€â”€ README.md                          # Service documentation
    â”œâ”€â”€ KUBESCAPE_ARCHITECTURE.md          # Kubescape integration details
    â”œâ”€â”€ KUBERNETES_SETUP.md                # K8s cluster setup guide
    â”œâ”€â”€ docker-compose.yml                 # Local development setup
    â”œâ”€â”€ kubescape-values.yaml              # Kubescape Helm configuration
    â”‚
    â”œâ”€â”€ api/                               # FastAPI REST API
    â”‚   â”œâ”€â”€ main.py                        # API endpoints
    â”‚   â””â”€â”€ schemas.py                     # Request/response models
    â”‚
    â”œâ”€â”€ workers/                           # Celery async workers
    â”‚   â”œâ”€â”€ tasks.py                       # Main task orchestration
    â”‚   â”œâ”€â”€ tasks_impl_kubescape.py        # Kubescape-based implementation
    â”‚   â””â”€â”€ celery_app.py                  # Celery configuration
    â”‚
    â”œâ”€â”€ services/                          # Business logic
    â”‚   â”œâ”€â”€ kubescape.py                   # Kubescape integration â­
    â”‚   â”œâ”€â”€ sandbox.py                     # K8s sandbox manager
    â”‚   â”œâ”€â”€ evidence.py                    # Evidence storage
    â”‚   â””â”€â”€ sbom.py                        # SBOM handling
    â”‚
    â”œâ”€â”€ models/                            # Database models
    â”‚   â””â”€â”€ analysis.py                    # Job tracking models
    â”‚
    â””â”€â”€ config/                            # Configuration
        â””â”€â”€ settings.py                    # Environment config
```

---

## Quick Start

### Prerequisites

1. **Docker & Docker Compose** - For running the service
2. **Kubernetes cluster** - For workload analysis
   - **Easiest:** Docker Desktop with Kubernetes enabled
   - **Alternatives:** minikube, kind, k3s, or cloud K8s
3. **kubectl** - Kubernetes CLI configured

### Step 1: Set Up Kubernetes

**Option A: Docker Desktop (Recommended for Mac/Windows)**
```bash
# Enable Kubernetes in Docker Desktop
# Settings â†’ Kubernetes â†’ Enable Kubernetes

# Verify it's running
kubectl get nodes
```

**Option B: minikube (Linux/Cross-platform)**
```bash
# Start minikube
minikube start --cpus=4 --memory=8192

# Verify
kubectl get nodes
```

See **[premium-service/KUBERNETES_SETUP.md](premium-service/KUBERNETES_SETUP.md)** for more options.

### Step 2: Start the Service

```bash
cd premium-service

# Start all services
docker-compose up -d

# Verify services are running
docker-compose ps

# Check worker can access Kubernetes
docker-compose exec worker kubectl get nodes
```

### Step 3: Submit Your First Analysis

```bash
# Submit a container image for analysis
curl -X POST http://localhost:8001/api/v1/analysis/submit \
  -H "Content-Type: application/json" \
  -d '{
    "image_ref": "nginx",
    "image_digest": "sha256:a72860cb95fd59a6782f590fb1c5c0fafbb5c59db6f3c17a28a4d5e1e32ba4a5",
    "config": {
      "analysis_duration": 300
    }
  }'

# Response includes job_id:
# {
#   "job_id": "550e8400-e29b-41d4-a716-446655440000",
#   "status": "queued",
#   ...
# }

# Check status (updates in real-time)
curl http://localhost:8001/api/v1/analysis/{job_id}/status

# Get results (after 6-11 minutes)
curl http://localhost:8001/api/v1/analysis/{job_id}/results
```

### What Happens

1. **Job queued** in Celery (0-5s)
2. **Kubescape installed** if not present (0-60s)
3. **Workload deployed** to Kubernetes sandbox (10-30s)
4. **Runtime analysis** by Kubescape with eBPF (5-10 min)
5. **VEX extracted** from Kubescape CRDs (10-20s)
6. **Results returned** with high-confidence reachability data

---

## Architecture

### Current Architecture (Kubescape-Based)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker Compose (Local Dev)        â”‚
â”‚                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ FastAPI (API Server)       â”‚    â”‚
â”‚   â”‚ port 8001                  â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Celery Worker              â”‚â”€â”€â”€â”€â”¼â”€â”€> kubectl commands
â”‚   â”‚ (Job Processing)           â”‚    â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚         â”‚
â”‚                                      â”‚         â–¼
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚ PostgreSQL (Jobs DB)       â”‚    â”‚   â”‚ Kubernetes Cluster   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚ (Separate)           â”‚
â”‚                                      â”‚   â”‚                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Redis (Task Queue)         â”‚    â”‚   â”‚ â”‚ vexxy-sandbox  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚ â”‚  namespace     â”‚  â”‚
â”‚                                      â”‚   â”‚ â”‚                â”‚  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚ â”‚ Deployments    â”‚  â”‚
â”‚   â”‚ Flower (Monitoring)        â”‚    â”‚   â”‚ â”‚ (workloads)    â”‚  â”‚
â”‚   â”‚ port 5555                  â”‚    â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                                           â”‚ â”‚ Kubescape      â”‚  â”‚
                                           â”‚ â”‚  operator      â”‚  â”‚
                                           â”‚ â”‚                â”‚  â”‚
                                           â”‚ â”‚ â€¢ eBPF monitor â”‚  â”‚
                                           â”‚ â”‚ â€¢ VEX CRDs     â”‚  â”‚
                                           â”‚ â”‚ â€¢ SBOM CRDs    â”‚  â”‚
                                           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Analysis Workflow

```
User â†’ API â†’ Celery â†’ K8s Deployment â†’ Kubescape â†’ VEX + SBOM
                â†“                           â†“             â†“
           PostgreSQL                    eBPF        Extract
          (job status)                 monitoring     CRDs
                                           â†“             â†“
                                      Runtime       Process &
                                      Analysis       Return
```

---

## What's Implemented

### âœ… Core Service (100%)
- FastAPI REST API with job submission
- Celery async task processing
- PostgreSQL job persistence
- Redis task queue
- Job status tracking with progress
- Evidence storage system

### âœ… Kubescape Integration (100%)
- Auto-detect and install Kubescape via Helm
- Deploy workloads as Kubernetes Deployments
- Wait for Kubescape runtime analysis
- Extract VEX from `OpenVulnerabilityExchangeContainer` CRDs
- Extract filtered SBOM from `SBOMSyftFiltered` CRDs
- Process and enhance VEX with VEXxy metadata

### âœ… Kubernetes Sandbox (100%)
- Deploy workloads in isolated namespace
- Resource limits (CPU, memory)
- Automatic cleanup after analysis
- Support for custom commands and environment variables

### âœ… Documentation (100%)
- Service README with quick start
- Kubescape architecture deep dive
- Kubernetes setup guide (5 options)
- Integration summary
- API endpoint documentation

### â³ In Progress
- Testing with real container images
- Production deployment guides
- Performance optimization
- Advanced configuration options

### ğŸ”® Future Enhancements
- Custom test script execution during runtime
- OWASP ZAP fuzzing for web applications
- gVisor runtime for extra isolation
- Multi-image comparison
- Scheduled re-analysis

---

## Key Features

### Real Reachability Analysis
- **Not mocked**: Uses actual Kubescape runtime monitoring
- **High confidence**: eBPF-based execution tracking
- **Production-grade**: Official CNCF-backed tooling

### Filtered SBOMs
- **Only relevant components**: Not the full SBOM
- **Runtime-based**: Only components actually used
- **Reduces noise**: Focus on what matters

### OpenVEX Documents
- **Standards-compliant**: OpenVEX 0.2.0 format
- **Rich evidence**: Runtime execution profiles
- **Cryptographic proof**: Signed attestations (future)

### Enterprise-Ready
- **Async processing**: Celery for scalability
- **Job tracking**: Real-time status updates
- **Evidence retention**: 90-day storage
- **Audit logs**: Full traceability

---

## Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **API** | FastAPI | REST API endpoints |
| **Workers** | Celery | Async job processing |
| **Queue** | Redis | Task queue & caching |
| **Database** | PostgreSQL | Job persistence |
| **Orchestration** | Kubernetes | Workload isolation |
| **Analysis** | Kubescape | Runtime VEX generation |
| **Monitoring** | Flower | Task monitoring UI |

---

## Configuration

### Environment Variables

```bash
# Database
DATABASE_URL=postgresql://vexxy:vexxy@postgres:5432/vexxy_premium

# Redis
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# Kubernetes
K8S_IN_CLUSTER=false                    # Use local kubeconfig
K8S_SANDBOX_NAMESPACE=vexxy-sandbox     # Namespace for analysis
KUBECONFIG=/root/.kube/config           # Path to kubeconfig

# Sandbox Limits
SANDBOX_CPU_LIMIT=2000m
SANDBOX_MEMORY_LIMIT=4Gi
SANDBOX_CPU_REQUEST=1000m
SANDBOX_MEMORY_REQUEST=2Gi

# Analysis
DEFAULT_ANALYSIS_DURATION=300           # 5 minutes
K8S_JOB_TTL_SECONDS=600                 # Cleanup after 10 min
```

---

## API Reference

### POST /api/v1/analysis/submit

Submit a container image for analysis.

**Request:**
```json
{
  "image_ref": "nginx",
  "image_digest": "sha256:abc123...",
  "config": {
    "analysis_duration": 300,
    "environment": {
      "PORT": "8080"
    },
    "command": ["/bin/sh", "-c", "sleep 600"]
  }
}
```

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "queued",
  "image_ref": "nginx",
  "image_digest": "sha256:abc123...",
  "estimated_duration_minutes": 10,
  "created_at": "2025-11-13T12:00:00Z"
}
```

### GET /api/v1/analysis/{job_id}/status

Get analysis job status.

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "running",
  "progress_percent": 35,
  "current_phase": "Runtime analysis",
  "created_at": "2025-11-13T12:00:00Z",
  "started_at": "2025-11-13T12:00:05Z"
}
```

### GET /api/v1/analysis/{job_id}/results

Get analysis results (available after completion).

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "complete",
  "summary": {
    "total_cves_analyzed": 15,
    "not_affected": 12,
    "affected": 2,
    "under_investigation": 1,
    "analysis_method": "kubescape_runtime_reachability",
    "confidence": "high"
  },
  "vex_document": {
    "@context": "https://openvex.dev/ns/v0.2.0",
    "statements": [...]
  },
  "completed_at": "2025-11-13T12:09:30Z"
}
```

---

## Monitoring

### Flower Dashboard

View real-time task processing:

```bash
# Access Flower UI
open http://localhost:5555

# Shows:
# - Active workers
# - Queued tasks
# - Task history
# - Success/failure rates
```

### Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f worker
docker-compose logs -f api

# Kubernetes resources
kubectl get deployments -n vexxy-sandbox
kubectl get pods -n kubescape
```

---

## Troubleshooting

### Job Stays Queued

```bash
# Check Celery worker is running
docker-compose ps worker

# Check worker logs
docker-compose logs worker

# Verify K8s connectivity
docker-compose exec worker kubectl get nodes
```

### Kubescape Not Found

```bash
# Check Kubescape installation
kubectl get pods -n kubescape

# Manually install
helm repo add kubescape https://kubescape.github.io/helm-charts
helm install kubescape kubescape/kubescape-operator \
  -n kubescape --create-namespace \
  -f premium-service/kubescape-values.yaml
```

### No VEX Generated

```bash
# Check Kubescape CRDs
kubectl get openvulnerabilityexchangecontainers -n kubescape

# Check filtered SBOMs
kubectl get sbomsyftfiltereds -n kubescape

# View Kubescape logs
kubectl logs -n kubescape -l app.kubernetes.io/name=kubevuln
```

See **[premium-service/KUBERNETES_SETUP.md](premium-service/KUBERNETES_SETUP.md)** for comprehensive troubleshooting.

---

## Development

### Running Tests

```bash
cd premium-service

# Unit tests
pytest tests/ -v

# Integration tests (requires K8s)
pytest tests/integration/ -v

# With coverage
pytest --cov=. --cov-report=html
```

### Code Quality

```bash
# Format code
black .

# Lint
flake8 .

# Type checking
mypy .
```

---

## Production Deployment

### Deploy to Kubernetes

For production, deploy the premium service **inside** Kubernetes (not docker-compose):

```yaml
# k8s/premium-service.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vexxy-premium-worker
  namespace: vexxy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: vexxy-premium-worker
  template:
    metadata:
      labels:
        app: vexxy-premium-worker
    spec:
      serviceAccountName: vexxy-premium
      containers:
      - name: worker
        image: vexxy-premium:latest
        command: ["celery", "-A", "workers.celery_app", "worker"]
        env:
        - name: K8S_IN_CLUSTER
          value: "true"  # Use in-cluster config
```

### Scaling

```bash
# Scale workers
kubectl scale deployment vexxy-premium-worker --replicas=5

# Enable HPA (Horizontal Pod Autoscaler)
kubectl autoscale deployment vexxy-premium-worker \
  --cpu-percent=70 \
  --min=3 \
  --max=10
```

---

## Documentation

### Service Documentation
- **[premium-service/README.md](premium-service/README.md)** - Service overview
- **[premium-service/KUBESCAPE_ARCHITECTURE.md](premium-service/KUBESCAPE_ARCHITECTURE.md)** - Deep dive
- **[premium-service/KUBERNETES_SETUP.md](premium-service/KUBERNETES_SETUP.md)** - K8s setup guide

### Integration Guides
- **[KUBESCAPE_INTEGRATION_SUMMARY.md](KUBESCAPE_INTEGRATION_SUMMARY.md)** - What we built
- **[PREMIUM_VEX_INTEGRATION_PLAN.md](PREMIUM_VEX_INTEGRATION_PLAN.md)** - Original plan (reference)

---

## License

**Proprietary** - VEXxy Enterprise Edition

The premium features in this repository are closed-source and licensed commercially.

---

## Support

**Questions?** Open a GitHub issue
**Documentation:** See [premium-service/](premium-service/)
**Kubernetes Issues:** See [KUBERNETES_SETUP.md](premium-service/KUBERNETES_SETUP.md)

---

## Status

**Current State:**
- âœ… Core service implemented and working
- âœ… Kubescape integration complete
- âœ… Docker Compose setup for local development
- âœ… Comprehensive documentation
- â³ Testing with real container images in progress
- ğŸ”® Production deployment coming soon

**Next Steps:**
1. Test with various container images
2. Performance optimization
3. Production deployment guides
4. Advanced features (custom tests, fuzzing, etc.)

---

**Built with â¤ï¸ for secure software supply chains**
